<!DOCTYPE html> 
<html>
    <head>
        <title> Companion Website </title>
        <link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'>
        <style>
        body {
    		font-family: 'Montserrat'; margin-left:201px; margin-right:151px
	     }
	</style>

    </head>
    <body>
	    <div class="container my_text" align="center">
	        <h1 style="color:brown;"> Tackling Interpretability in Audio Classification Networks with Non-negative Matrix Factorization </h1>
		<p style="color:darkblue;">TASLP submission page</p>
	    </div>
		
		<h2 style="color:brown;" id='code' align="center"> Abstract </h2>

		<p> 
		  This paper tackles two major problem settings for interpretability of audio processing networks, post-hoc and by-design interpretation. 
		  For post-hoc interpretation, we aim to interpret decisions of a network in terms of high-level audio objects that are also listenable for the end-user. 
		  This is extended to present an inherently interpretable model with high performance. To this end, we propose a novel interpreter design that incorporates non-negative matrix factorization (NMF). In particular, an interpreter is trained to generate a regularized intermediate embedding from hidden layers of a target network, learnt as time-activations of a pre-learnt NMF dictionary. Our methodology allows us to generate intuitive audio-based interpretations that explicitly enhance parts of the input signal most relevant for a network's decision. We demonstrate our method's applicability on a variety of classification tasks, including multi-label data for real-world audio and music. Our <a href="https://github.com/jayneelparekh/L2I-code">implementation</a> is on github
                <br>

                <p style="padding: 10px; border: 2px solid red;"> It's worth emphasizing that audio interpretability is <b> not </b> the same as classical audio tasks of separation or denoising. These tasks involve recovering complete object of interest in the output audio. On the other hand, a classifier network might focus more on salient regions. When interpreting its decision and making it listenable we expect to uncover such regions and not necessarily the complete object of interest. </p>



                <ul>
                    <li> <a class="active" href="#esc50_overlap">ESC50 examples</a> <br>
                        <ul>
                            <li> <a class="active" href="#esc50_overlap">Corruption from a different class (Overlap experiment)</a>  </li> 
                            <li> <a class="active" href="#esc50_noise">Corruption with 0dB noise (Noise experiment)</a>  </li>
                            <li> <a class="active" href="#other_esc50_noise", style="color:blue">Other method interpretations (Noise experiment) </a> </li>
                            <li> <a class="active" href="#misclassify">Misclassification examples (with 0dB noise)</a> </li>
                        </ul> 
                    </li> <br>
                    <li> <a class="active" href="#sonyc_ust">SONYC-UST examples</a> </li> <br>
                    <li> <a class="active" href="#openmic">OpenMIC-2018 examples</a> </li> <br>
                    <li> <a class="active" href="appendix.pdf">Supplementary discussion</a> </li>
                </ul>
		
		
		<br>
	
                <ul>
                     <li> Chrome is the preferred browser. The samples may not always run in Firefox. </li> <br>
                     <li> Use of headphones/earphones recommended. </li> <br>
                     <li> <b> Please tune your volume appropriately before playing any sample. </b> </li> <br>
                     <li> <mark> The audio files may take some time to load. </mark> If they do not load even after waiting, it can be a temporary hosting server issue. In that case, please visit again after sometime</li> <br>
                </ul>
             
 

            <br>


            <h2 style="color:brown;" id='esc50_overlap'> Audio Samples: ESC50 with Corruption from different class </h2>

            <p> Example interpretations on ESC50-fold 1 test data, where samples are corrupted with audio from a different class are given below. </p>

            <p> For each sample you can listen to the input audio to the classifier, and interpretation audio for the class predicted by the classifier. Additionally, you can view four spectrograms to further support observations from listening to interpretations: (i) Uncorrupted target class signal (Top-Left), (ii) Corrupting/Mixing class signal (Top-right), (iii) Corrupted/mixed signal, also the input audio for classifier (Bottom-Left), (iv) Interpretation audio (Bottom-Right) </p>
            

            <h4 style="color:darkblue;"> Sample A </h4>
            <p> Predicted class by the classifier: 'DOG' (classifier probability: 0.713) </p>
            <p> Target class: 'DOG' &nbsp &nbsp  &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp  &nbsp &nbsp &nbsp &nbsp Corrupting class: 'CRYING-BABY' </p>
            <img src="qualitative/ESC50_overlap/Sample_157_300_intensity0.15/original_157_spec.png" alt="A_spectrogram_target_class" width="256" height="256">
            <img src="qualitative/ESC50_overlap/Sample_157_300_intensity0.15/mixer_300_spec.png" alt="A_spectrogram_corrupt_class" width="256" height="256">
            <table>
                <tr><td style="color:brown;"> Input sample &emsp; &emsp; &emsp; </td> <td> <audio controls> <source src= "qualitative/ESC50_overlap/Sample_157_300_intensity0.15/original_157_300.wav" type="audio/wav"> </audio> </td></tr>  
	        <tr><td style="color:brown;"> Interpretation audio &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/ESC50_overlap/Sample_157_300_intensity0.15/Expl_157.wav" type="audio/wav">   </audio> </td> </tr>
            </table>
            <img src="qualitative/ESC50_overlap/Sample_157_300_intensity0.15/original_157_300_spec.png" alt="A_spectrogram_input" width="256" height="256">
            <img src="qualitative/ESC50_overlap/Sample_157_300_intensity0.15/Expl_157_spec.png" alt="A_spectrogram_interpretation" width="256" height="256">
            <br> <br> <br>


            <h4 style="color:darkblue;"> Sample B </h4>
            <p> Predicted class by the classifier: 'CRYING-BABY' (classifier probability: 0.998) </p>
            <p> Target class: 'CRYING-BABY'  &nbsp &nbsp  &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp  &nbsp &nbsp  Corrupting class: 'DOG'</p>
            <img src="qualitative/ESC50_overlap/Sample_300_157_intensity0.6/original_300_spec.png" alt="B_spectrogram_target_class" width="256" height="256">
            <img src="qualitative/ESC50_overlap/Sample_300_157_intensity0.6/mixer_157_spec.png" alt="B_spectrogram_corrupt_class" width="256" height="256">
            <table>
                <tr><td style="color:brown;"> Input sample &emsp; &emsp; &emsp; </td> <td> <audio controls> <source src= "qualitative/ESC50_overlap/Sample_300_157_intensity0.6/original_300_157.wav" type="audio/wav"> </audio> </td></tr> 
	        <tr><td style="color:brown;"> Interpretation audio &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/ESC50_overlap/Sample_300_157_intensity0.6/Expl_300.wav" type="audio/wav">   </audio> </td> </tr>
            </table>
            <img src="qualitative/ESC50_overlap/Sample_300_157_intensity0.6/original_300_157_spec.png" alt="B_spectrogram_input" width="256" height="256"> 
            <img src="qualitative/ESC50_overlap/Sample_300_157_intensity0.6/Expl_300_spec.png" alt="B_spectrogram_interpretation" width="256" height="256"> 
            <br> <br> <br>


            <h4 style="color:darkblue;"> Sample C </h4>
            <p> Predicted class by the classifier: 'CHURCH-BELL' (classifier probability: 0.999) </p>
            <p> Target class: 'CHURCH-BELL' &nbsp &nbsp  &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp  &nbsp &nbsp &nbsp &nbsp Corrupting class: 'ROOSTER' </p>
            <img src="qualitative/ESC50_overlap/Sample_199_178_Bell_Rooster/original_199_spec.png" alt="C_spectrogram_target_class" width="256" height="256">
            <img src="qualitative/ESC50_overlap/Sample_199_178_Bell_Rooster/mixer_178_spec.png" alt="C_spectrogram_corrupt_class" width="256" height="256">
            <table>
                <tr> <td style="color:brown;"> Input sample &emsp; &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/ESC50_overlap/Sample_199_178_Bell_Rooster/original_199_178.wav" type="audio/wav"> </audio> </td></tr>  
	        <tr> <td style="color:brown;"> Interpretation audio &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/ESC50_overlap/Sample_199_178_Bell_Rooster/Expl_199.wav" type="audio/wav">   </audio> </td> </tr>
            </table>
            <img src="qualitative/ESC50_overlap/Sample_199_178_Bell_Rooster/original_199_178_spec.png" alt="C_spectrogram_input" width="256" height="256">
            <img src="qualitative/ESC50_overlap/Sample_199_178_Bell_Rooster/Expl_199_spec.png" alt="C_spectrogram_interpretation" width="256" height="256">
            <br> <br> <br>


            <h4 style="color:darkblue;"> Sample D </h4>
            <p> Predicted class by the classifier: 'DOG' (classifier probability: 0.999)</p>
            <p> Target class: 'DOG' &nbsp &nbsp  &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp  &nbsp &nbsp &nbsp &nbsp Corrupting class: 'CAT' </p>
            <img src="qualitative/ESC50_overlap/Sample_157_229_intensity0.09/original_157_spec.png" alt="D_spectrogram_target_class" width="256" height="256">
            <img src="qualitative/ESC50_overlap/Sample_157_229_intensity0.09/mixer_229_spec.png" alt="D_spectrogram_corrupt_class" width="256" height="256">
            <table>
                <tr> <td style="color:brown;"> Input sample &emsp; &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/ESC50_overlap/Sample_157_229_intensity0.09/original_157_229.wav" type="audio/wav"> </audio> </td></tr>  
	        <tr> <td style="color:brown;"> Interpretation audio &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/ESC50_overlap/Sample_157_229_intensity0.09/Expl_157.wav" type="audio/wav">   </audio> </td> </tr>
            </table>
            <img src="qualitative/ESC50_overlap/Sample_157_229_intensity0.09/original_157_229_spec.png" alt="D_spectrogram_input" width="256" height="256">
            <img src="qualitative/ESC50_overlap/Sample_157_229_intensity0.09/Expl_157_spec.png" alt="D_spectrogram_interpretation" width="256" height="256">
            <br> <br> <br>




 
            <br> <br> <br> <br> <br> <br>
          
		
	    <h2 style="color:brown;" id='esc50_noise'> Audio Samples: ESC50 with Noise (0dB SNR) </h2>

            <p> Some example interpretations on ESC50-fold 1 test data, corrupted with white noise at 0dB SNR are given below. </p>

            <p> For each sample you can listen to the input to the classifier, and interpretation audio for the class predicted by the classifier. Again, as the corrupting signal is already known, we further support the observations by listening to interpretations with spectrograms for (i) Input audio (corrupted with white noise), (ii) Interpretation audio. In all cases the noise in interpretation audio is significantly reduced compared to input and the most emphasis is on part of input from class of interest </p>
            
		
            <h4 style="color:darkblue;"> Sample A </h4>
            <p> Predicted class by the classifier: 'ROOSTER' (classifier probability: 0.964) </p>
            <table>
                <tr> <td style="color:brown;"> Input sample &emsp; &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/ESC50_Noise/original_178.wav" type="audio/wav"> </audio> </td></tr>  
	        <tr> <td style="color:brown;"> Interpretation audio &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/ESC50_Noise/Expl_178.wav" type="audio/wav">   </audio> </td> </tr>
            </table>
            <img src="qualitative/ESC50_Noise/original_178_spec.png" alt="D_spectrogram_interpretation" width="256" height="256">
            <img src="qualitative/ESC50_Noise/Expl_178_spec.png" alt="D_spectrogram_interpretation" width="256" height="256">
            <br>

            <h4 style="color:darkblue;"> Sample B </h4>
            <p> Predicted class by the classifier: 'CAT' (classifier probability: 0.978) </p>
            <table>
                <tr><td style="color:brown;"> Input sample &emsp; &emsp; &emsp; </td> <td> <audio controls> <source src= "qualitative/ESC50_Noise/original_229.wav" type="audio/wav"> </audio> </td> </tr> 
                <tr><td style="color:brown;"> Interpretation audio &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/ESC50_Noise/Expl_229.wav" type="audio/wav">   </audio> </td> </tr>
            </table>
            <img src="qualitative/ESC50_Noise/original_229_spec.png" alt="D_spectrogram_interpretation" width="256" height="256">
            <img src="qualitative/ESC50_Noise/Expl_229_spec.png" alt="D_spectrogram_interpretation" width="256" height="256">
            <br>

            <h4 style="color:darkblue;"> Sample C </h4>
            <p> Predicted class by the classifier: 'SHEEP' (classifier probability: 0.998) </p>
            <table>
                <tr><td style="color:brown;"> Input sample &emsp; &emsp; &emsp; </td> <td> <audio controls> <source src= "qualitative/ESC50_Noise/original_237.wav" type="audio/wav"> </audio> </td></tr>  
	        <tr><td style="color:brown;"> Interpretation audio &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/ESC50_Noise/Expl_237.wav" type="audio/wav">   </audio> </td> </tr>
            </table>
            <img src="qualitative/ESC50_Noise/original_237_spec.png" alt="D_spectrogram_interpretation" width="256" height="256">
            <img src="qualitative/ESC50_Noise/Expl_237_spec.png" alt="D_spectrogram_interpretation" width="256" height="256">
            <br> 



            <br> <br> <br> <br> <br> <br>


            
            <h2 style="color:brown;" id='other_esc50_noise'> Other methods interpretations (0dB SNR noise) </h2>

            <h3> IBA Attribution </h3>

            <p> Example interpretations generated using an attribution map approach on ESC50-fold 1 test data, corrupted with white noise at 0dB SNR are given below. </p>

            <p> Experimental details: We used the python PyTorch version of their package and follow the standard example version given as example on their webpage (repository link: https://github.com/BioroboticsLab/IBA). They insert a bottleneck in conv layer from 4th block of VGG16. Our network architecture is also similar to VGG architectures. So we applied a bottleneck at the output of 4th conv block, which we also access via our interpreter. They use Adam optimization for 10 iterations and we follow the same procedure through their package. The saliency map is applied on the mel-spectrogram and then STFT is approximated and finally inverted to time-domain using input phase for a time-domain audio output. </p>

            <p> For each sample you can listen to the input to the classifier, and IBA interpretation audio for the predicted class. We also show the saliency maps on mel-spectrogram space generated using IBA. From the time of activations in the saliency maps below, it is clear that IBA visually identifies relevant regions, but as an audio filter it is poor given the high amount of noise still in the interpretations. A very interesting observation is that the brightest spot of saliency map in time corresponds to most emphasized signal in our interpretations (for both examples), which just reinforce insights from our system, given the significant methodological differences of obtaining the two.</p>
            
		
            <h4 style="color:darkblue;"> Sample A </h4>
            <p> Predicted class by the classifier: 'ROOSTER' </p>
            <table>
                <tr> <td style="color:brown;"> Input sample &emsp; &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/IBA_Noise/iba_original_178.wav" type="audio/wav"> </audio> </td></tr>  
	        <tr> <td style="color:brown;"> IBA Interpretation audio &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/IBA_Noise/iba_Expl_178.wav" type="audio/wav">   </audio> </td> </tr>
            </table>
            <img src="qualitative/IBA_Noise/iba_178_inp_spec.png" alt="A_LMspectrogram_input" width="256" height="256">
            <img src="qualitative/IBA_Noise/iba_178_expl_spec.png" alt="A_LMspectrogram_interpretation" width="256" height="256">
            <img src="qualitative/IBA_Noise/iba_178_saliency.png" alt="A_LMspectrogram_interpretation" width="700" height="256">
            <br>


            <h4 style="color:darkblue;"> Sample C </h4>
            <p> Predicted class by the classifier: 'SHEEP' </p>
            <table>
                <tr><td style="color:brown;"> Input sample &emsp; &emsp; &emsp; </td> <td> <audio controls> <source src= "qualitative/IBA_Noise/iba_original_237.wav" type="audio/wav"> </audio> </td></tr>  
	        <tr><td style="color:brown;"> IBA Interpretation audio &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/IBA_Noise/iba_Expl_237.wav" type="audio/wav">   </audio> </td> </tr>
            </table>
            <img src="qualitative/IBA_Noise/iba_237_inp_spec.png" alt="C_LMspectrogram_input" width="256" height="256">
            <img src="qualitative/IBA_Noise/iba_237_expl_spec.png" alt="C_LMspectrogram_interpretation" width="256" height="256">
            <img src="qualitative/IBA_Noise/iba_237_saliency.png" alt="A_LMspectrogram_interpretation" width="700" height="266">
            <br> 

            <br> <br> <br>

            <h3> FLINT Visualization and audio </h3>

            <p> Local interpretations with FLINT on ESC50-fold 1 test data, corrupted with white noise at 0dB SNR are given below. </p>

            <p> </p>

            <h4 style="color:darkblue;"> Sample A </h4>
            <p> Predicted class by the classifier: 'ROOSTER' </p>
            <table>
                <tr> <td style="color:brown;"> Input sample &emsp; &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/FLINT_Noise/original_178.wav" type="audio/wav"> </audio> </td></tr>  
	        <tr> <td style="color:brown;"> FLINT interpretation audio (Attribute 77) &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/FLINT_Noise/Samp_178_attr77_class1.wav" type="audio/wav">   </audio> </td> </tr>
                <tr> <td style="color:brown;"> FLINT interpretation audio (Attribute 62) &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/FLINT_Noise/Samp_178_attr62_class1.wav" type="audio/wav">   </audio> </td> </tr>
            </table>
            <img src="qualitative/FLINT_Noise/flint_178_inpspec.png" alt="A_LMspectrogram_input" width="256" height="256">
            <img src="qualitative/FLINT_Noise/ampi_178_attr77_spec.png" alt="A_FLINT_LMspectrogram_interpretation" width="256" height="256">
            <img src="qualitative/FLINT_Noise/ampi_178_attr62_spec.png" alt="A_FLINT_LMspectrogram_interpretation" width="256" height="256">
            <br> <br>

            <h4 style="color:darkblue;"> Sample C </h4>
            <p> Predicted class by the classifier: 'SHEEP' </p>
            <table>
                <tr> <td style="color:brown;"> Input sample &emsp; &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/FLINT_Noise/original_237.wav" type="audio/wav"> </audio> </td></tr>  
	        <tr> <td style="color:brown;"> FLINT interpretation audio (Attribute 77) &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/FLINT_Noise/Samp_237_attr77_class8.wav" type="audio/wav">   </audio> </td> </tr>
                <tr> <td style="color:brown;"> FLINT interpretation audio (Attribute 7) &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/FLINT_Noise/Samp_237_attr7_class8.wav" type="audio/wav">   </audio> </td> </tr>
            </table>
            <img src="qualitative/FLINT_Noise/flint_237_inpspec.png" alt="C_LMspectrogram_input" width="256" height="256">
            <img src="qualitative/FLINT_Noise/ampi_237_attr77_spec.png" alt="C_FLINT_LMspectrogram_interpretation" width="256" height="256">
            <img src="qualitative/FLINT_Noise/ampi_237_attr7_spec.png" alt="C_FLINT_LMspectrogram_interpretation" width="256" height="256">
            <br>

            <br> <br> <br>
            

            <h3> Guided-Backpropagation </h3>

            <h4 style="color:darkblue;"> Sample A </h4>
            <p> Predicted class by the classifier: 'ROOSTER' </p>
            <table>
                <tr> <td style="color:brown;"> Input sample &emsp; &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/IBA_Noise/iba_original_178.wav" type="audio/wav"> </audio> </td></tr>  
	        <tr> <td style="color:brown;"> GuidedBackprop Interpretation audio &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/GBP_Noise/gbp_178_final2.wav" type="audio/wav">   </audio> </td> </tr>
            </table>
            <img src="qualitative/IBA_Noise/iba_178_inp_spec.png" alt="A_LMspectrogram_input" width="256" height="256">
            <img src="qualitative/GBP_Noise/gbp_178_expl_spec.png" alt="A_LMspectrogram_interpretation" width="256" height="256">
            <br>


            <h4 style="color:darkblue;"> Sample C </h4>
            <p> Predicted class by the classifier: 'SHEEP' </p>
            <table>
                <tr><td style="color:brown;"> Input sample &emsp; &emsp; &emsp; </td> <td> <audio controls> <source src= "qualitative/IBA_Noise/iba_original_237.wav" type="audio/wav"> </audio> </td></tr>  
	        <tr><td style="color:brown;"> GuidedBackprop Interpretation audio &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/GBP_Noise/gbp_237_final2.wav" type="audio/wav">   </audio> </td> </tr>
            </table>
            <img src="qualitative/IBA_Noise/iba_237_inp_spec.png" alt="C_LMspectrogram_input" width="256" height="256">
            <img src="qualitative/GBP_Noise/gbp_237_expl_spec.png" alt="C_LMspectrogram_interpretation" width="256" height="256">
            <br> 


            <br> <br> <br> <br> <br> <br>



            <h2 style="color:brown;" id='misclassify'> ESC50-Misclassification examples (with 0dB noise) </h2>

            <h4 style="color:darkblue;"> Sample A </h4>
            <p> Predicted class by the classifier: 'CAR-HORN' (classifier probability: 0.931) &nbsp &nbsp  &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp  &nbsp &nbsp  Ground truth class: 'CRYING-BABY' </p>
            <table>
                <tr> <td style="color:brown;"> Input sample &emsp; &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/ESC50_Misclassify/original_300.wav" type="audio/wav"> </audio> </td></tr>  
	        <tr> <td style="color:brown;"> Interpretation audio (for predicted class) &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/ESC50_Misclassify/Expl_300.wav" type="audio/wav">   </audio> </td> </tr>
            </table>
            <br>

            <h4 style="color:darkblue;"> Sample B </h4>
            <p> Predicted class by the classifier: 'GLASS-BREAKING' (classifier probability: 0.437) &nbsp &nbsp  &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp  &nbsp &nbsp Ground truth class: 'CAN-OPENING' </p>
            <table>
                <tr> <td style="color:brown;"> Input sample &emsp; &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/ESC50_Misclassify/original_323.wav" type="audio/wav"> </audio> </td></tr>  
	        <tr> <td style="color:brown;"> Interpretation audio (for predicted class) &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/ESC50_Misclassify/Expl_323.wav" type="audio/wav">   </audio> </td> </tr>
            </table>
            <br>

            <br> <br> <br> <br> <br> <br>  



            <h2 style="color:brown;" id='sonyc_ust'> Audio Samples: SONYC-UST examples </h2>


            <h3 style="color:darkblue;"> Example interpretations for class 'ALERT SIGNAL' (car/truck horns, sirens, alarm) </h3>
            <p> Sample 1 contains two horns towards the end of audio. Interpretation almost entirely filters out noise, very clearly emphasizes the two horns. <br> <br> Sample 2 contains heavy noise with very weak presence of horns. The prominent one being around 5 second mark. However, the interpretation is able to emphasize this horn and filter out most of other signals. </p>
            <table>
                <tr> 
                     <td style="color:brown;"> Sample 1 &emsp; &emsp; </td> <td> <audio controls> <source src= "qualitative/SONYC_UST/original_302.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Sample 2 &emsp; &emsp; </td> <td> <audio controls> <source src= "qualitative/SONYC_UST/original_13.wav" type="audio/wav"> </audio> </td> 
                </tr>  
	        <tr>
                     <td style="color:brown;"> Interpretation 1 &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/SONYC_UST/Expl_302Cl_4.wav" type="audio/wav">   </audio> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; </td> 
                     <td style="color:brown;"> Interpretation 2 &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/SONYC_UST/Expl_13Cl_4.wav" type="audio/wav">   </audio>
                </tr>
            </table>

            <br> <br>
            <h3 style="color:darkblue;"> Example interpretations for class 'DOG' </h3>
            <p> Both samples contain singular dog barks which are emphasized in the interpretation, simultaneously filtering out most other signals </p>
            <table>
                <tr> 
                     <td style="color:brown;"> Sample 1 &emsp; &emsp; </td> <td> <audio controls> <source src= "qualitative/SONYC_UST/original_414.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Sample 2 &emsp; &emsp; </td> <td> <audio controls> <source src= "qualitative/SONYC_UST/original_582.wav" type="audio/wav"> </audio>
                </tr>  
	        <tr>
                     <td style="color:brown;"> Interpretation 1 &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/SONYC_UST/Expl_414Cl_7.wav" type="audio/wav">   </audio> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; </td> 
                     <td style="color:brown;"> Interpretation 2 &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/SONYC_UST/Expl_582Cl_7.wav" type="audio/wav">
                </tr>
            </table>

            <br> <br>
            <h3 style="color:darkblue;"> Example interpretations for class 'MUSIC' </h3>
            <p> Sample 1 contains weak music signal with high intensity of other signals (background noise, chirping birds etc.). Interpretation suppresses most of other signals from time frames where music is not present. It also clearly emphasizes the music signal although some background noise is also captured with it. It is still good indicator of classifier making the decision based on actually detecting the music signal. <br> <br> Sample 2 contains relatively strong music signal along with reasonable strength of noise and human voices. The interpretation significantly suppresses human voices, and to some extent the background noise while clearly emphasizing the music signal. </p>
            <table>
                <tr> 
                     <td style="color:brown;"> Sample 1 &emsp; &emsp; </td> <td> <audio controls> <source src= "qualitative/SONYC_UST/original_391.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Sample 2 &emsp; &emsp; </td> <td> <audio controls> <source src= "qualitative/SONYC_UST/original_107.wav" type="audio/wav"> </audio>
                </tr>  
	        <tr>
                     <td style="color:brown;"> Interpretation 1 &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/SONYC_UST/Expl_391Cl_5.wav" type="audio/wav">   </audio> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; </td> 
                     <td style="color:brown;"> Interpretation 2 &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/SONYC_UST/Expl_107Cl_5.wav" type="audio/wav">   </audio>
                </tr>
            </table>



            <br> <br>
            <h3 style="color:darkblue;"> Examples for full sample interpretations </h3>
            <table>
                <tr> 
                     <td style="color:brown;"> Sample 1 &emsp; &emsp; </td> <td> <audio controls> <source src= "qualitative/SONYC_UST/original_519.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Sample 2 &emsp; &emsp; </td> <td> <audio controls> <source src= "qualitative/SONYC_UST/original_616.wav" type="audio/wav"> </audio>
                </tr>  

                <tr>
                     <td> Predicted classes: 'ALERT-SIGNAL', 'HUMAN'  </td> <td> </td>
                     <td> Predicted classes: 'ALERT-SIGNAL', 'MUSIC', 'HUMAN'</td>  <td> </td>
                </tr>

	        <tr>
                     <td style="color:brown;"> Interpretation 1 - 'ALERT-SIGNAL' &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/SONYC_UST/Expl_519Cl_4.wav" type="audio/wav">   </audio> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; </td>  
                     <td style="color:brown;"> Interpretation 2 - 'ALERT-SIGNAL' &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/SONYC_UST/Expl_616Cl_4.wav" type="audio/wav">   </audio>
                </tr>
 
                <tr>
                     <td style="color:brown;"> Interpretation 1 - 'HUMAN' &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/SONYC_UST/Expl_519Cl_6.wav" type="audio/wav">   </audio> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; </td>  
                     <td style="color:brown;"> Interpretation 2 - 'MUSIC' &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/SONYC_UST/Expl_616Cl_5.wav" type="audio/wav">   </audio>
                </tr>

                <tr>
                     <td>   </td> <td> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; </td>  
                     <td style="color:brown;"> Interpretation 2 - 'HUMAN' (Poor Interpretation) &emsp; &emsp; </td> <td> <audio controls>  <source src= "qualitative/SONYC_UST/Expl_616Cl_6.wav" type="audio/wav">   </audio>
                </tr>

                <tr>
                    <td> </td> <td> </td>
                    <td> <p> This sample is quite difficult for class 'HUMAN'. The human voices are considerably weak in intensity and dominated by other classes and noise. 
                              </p> </td>  <td> </td>
                </tr>
            </table>

          

            <h2 style="color:brown;" id='openmic'> Audio Samples: OpenMIC-2018 examples </h2>

            <h3 style="color:darkblue;"> Example interpretations for class 'BASS' </h3>
            <p>  </p>
            <table>
                <tr> 
                     <td style="color:brown;"> Sample 1 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_68.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Sample 2 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_749.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Sample 3 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_1478.wav" type="audio/wav"> </audio> </td>
                </tr>  
	        <tr>
                     <td style="color:brown;"> Interpretation 1 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_68Cl_2.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td> 
                     <td style="color:brown;"> Interpretation 2 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_749Cl_2.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>  
                     <td style="color:brown;"> Interpretation 3 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_1478Cl_2.wav" type="audio/wav"> </audio> </td> 
                </tr>
            </table>

            <br> <br>


            <h3 style="color:darkblue;"> Example interpretations for class 'FLUTE' </h3>
            <p>  </p>
            <table>
                <tr> 
                     <td style="color:brown;"> Sample 1 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_2632.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Sample 2 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_763.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Sample 3 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_4822.wav" type="audio/wav"> </audio> </td>
                </tr>  
	        <tr>
                     <td style="color:brown;"> Interpretation 1 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_2632Cl_7.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Interpretation 2 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_763Cl_7.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>  
                     <td style="color:brown;"> Interpretation 3 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_4822Cl_7.wav" type="audio/wav"> </audio> </td> 
                </tr>
            </table>

            <br> <br>


            <h3 style="color:darkblue;"> Example interpretations for class 'VIOLIN' </h3>
            <p>  </p>
            <table>
                <tr> 
                     <td style="color:brown;"> Sample 1 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_4299.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Sample 2 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_3900.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Sample 3 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_4524.wav" type="audio/wav"> </audio> </td>
                </tr>  
	        <tr>
                     <td style="color:brown;"> Interpretation 1 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_4299Cl_18.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Interpretation 2 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_3900Cl_18.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>  
                     <td style="color:brown;"> Interpretation 3 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_4524Cl_18.wav" type="audio/wav"> </audio> </td> 
                </tr>
            </table>

            <br> <br>


            <h3 style="color:darkblue;"> Example interpretations for class 'GUITAR' </h3>
            <p>  </p>
            <table>
                <tr> 
                     <td style="color:brown;"> Sample 1 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_2780.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Sample 2 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_4413.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Sample 3 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_4989.wav" type="audio/wav"> </audio> </td>
                </tr>  
	        <tr>
                     <td style="color:brown;"> Interpretation 1 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_2780Cl_8.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Interpretation 2 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_4413Cl_8.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>  
                     <td style="color:brown;"> Interpretation 3 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_4989Cl_8.wav" type="audio/wav"> </audio> </td> 
                </tr>
            </table>

            <br> <br>


            <h3 style="color:darkblue;"> Example interpretations for class 'PIANO' </h3>
            <p>  </p>
            <table>
                <tr> 
                     <td style="color:brown;"> Sample 1 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_1409.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Sample 2 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_2496.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Sample 3 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_4740.wav" type="audio/wav"> </audio> </td>
                </tr>  
	        <tr>
                     <td style="color:brown;"> Interpretation 1 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_1409Cl_12.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Interpretation 2 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_2496Cl_12.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>  
                     <td style="color:brown;"> Interpretation 3 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_4740Cl_12.wav" type="audio/wav"> </audio> </td> 
                </tr>
            </table>

            <br> <br>


            <h3 style="color:darkblue;"> Example interpretations for classes 'SAXOPHONE/TROMBONE/TRUMPET' </h3>
            <p>  </p>
            <table>
                <tr> 
                     <td style="color:brown;"> Sample 1 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_676.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Sample 2 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_1002.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Sample 3 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_1093.wav" type="audio/wav"> </audio> </td>
                </tr>  
	        <tr>
                     <td style="color:brown;"> Interpretation 1 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_676Cl_13.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Interpretation 2 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_1002Cl_13.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>  
                     <td style="color:brown;"> Interpretation 3 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_1093Cl_16.wav" type="audio/wav"> </audio> </td> 
                </tr>
            </table>

            <br> <br>

            <h3 style="color:darkblue;"> Example interpretations for class 'ORGAN' </h3>
            <p>  </p>
            <table>
                <tr> 
                     <td style="color:brown;"> Sample 1 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_3008.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Sample 2 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_4493.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Sample 3 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_4709.wav" type="audio/wav"> </audio> </td>
                </tr>  
	        <tr>
                     <td style="color:brown;"> Interpretation 1 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_3008Cl_11.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Interpretation 2 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_4493Cl_11.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>  
                     <td style="color:brown;"> Interpretation 3 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_4709Cl_11.wav" type="audio/wav"> </audio> </td> 
                </tr>
            </table>

            <br> <br>


            <h3 style="color:darkblue;"> Example interpretations for class 'MALLET-PERCUSSION' </h3>
            <p>  </p>
            <table>
                <tr> 
                     <td style="color:brown;"> Sample 1 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_547.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Sample 2 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_933.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Sample 3 &emsp; </td> <td> <audio controls> <source src= "qualitative/OpenMIC/original_1161.wav" type="audio/wav"> </audio> </td>
                </tr>  
	        <tr>
                     <td style="color:brown;"> Interpretation 1 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_547Cl_9.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>
                     <td style="color:brown;"> Interpretation 2 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_933Cl_9.wav" type="audio/wav"> </audio> &emsp; &emsp; &emsp; &emsp; &emsp; </td>  
                     <td style="color:brown;"> Interpretation 3 &emsp; </td> <td> <audio controls>  <source src= "qualitative/OpenMIC/Expl_1161Cl_9.wav" type="audio/wav"> </audio> </td> 
                </tr>
            </table>

            <br> <br>



            <h2 style="color:brown;" id='baselines'> Baseline implementation details </h2>
             
                <ol>

                    <li> <b> FLINT: </b> We implemented it with the help of their <a href="https://github.com/jayneelparekh/FLINT">official implementation</a> available on GitHub. For each experiment, we fix their number of attributes J equal to the number of our NMF components K. We also choose the same hidden layers for their system as we choose for ours. This baseline is trained for the same number of epochs as us. We use same values for our NMF loss weight, and their input fidelity loss weight. For the other loss hyperparameters, we use their default values and training strategy. </li>
                    <br> <br>
                    <li> <b> VIBI: </b> We implemented this using their <a href="https://github.com/SeojinBang/VIBI">official repository</a>. The key hyperparameters that we set are the input chunk size and their parameter K, the number of chunks to use for interpretation. We use a larger chunk size than in their experiments to limit the number of chunks. On ESC-50, we use a chunk size of 32 X 43, and on SONYC-UST, a chunk size of 32 X 86. This yields 40 chunks for each input on both the datasets. We varied the K from 5 to 20, and report the results with best fidelity. The system was trained for 100 epochs on ESC-50 and 30 epochs on SONYC-UST.  </li>
                    <br> <br>
                    <li> <b> SLIME: </b> We primarily relied on implementation from their <a href="https://github.com/saum25/local_exp_robustness">robustness analysis repository</a>. The key hyperparameters to balance are the number of chunks vs chunk size. SONYC-UST contains 10 second audio files. This is much longer than 1.6 second audio files for which SLIME was originally demonstrated. Therefore, we divide only on the time-axis to limit the number of chunks. SLIME recommends a chunk size of at least 100ms. They operate on upto 290ms chunk size. We balance these two hyperparameters by dividing our audio files in 20 chunks of 500ms chunk size. We select a maximum of 5 chunks for interpretations and a neighbourhood size of 1000. </li>
                    <br> <br>
                    <li> <b> APNet: </b> We utilized their <a href="https://github.com/pzinemanas/APNet">source code</a> for implementing their method on our datasets. We did not modify their network design or loss weights and set the number of prototypes same as our number of components. The number of mel filters was chosen between 64 and 128. We trained their system for 100 epochs on ESC-50 (each fold) and 21 epochs for SONYC-UST and OpenMIC-2018 and report the highest recorded metrics.  </li>
                    <br> <br>
                    <li> <b> NMF variants: </b> For implementing both TDL-NMF and Unsupervised-NMF, we utilized the <a href="https://github.com/rserizel/TGNMF">source repository</a> of TDL-NMF. The unsupervised-NMF variant simply trains a linear model on top of generated time activations for predictions while the dictionary is also updated with classification loss for TDL-NMF. We trained dictionaries of multiple sizes, ranging from 32 to 256 for each dataset and two different audio representations, log-magnitude spectrogram and mel-spectrogram. The best performance among all these configurations is reported.  </li>

                </ol>

                
		
    </body>
</html>
